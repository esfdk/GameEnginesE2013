\section{Issues}
\label{Issues}

While our testing confirmed that the plug-in worked, we did run into some issues.

\subsection{Data from multiple files}
\label{Issues_MoreFiles}

As the plug-in lets the user choose which file to load data from, it is possible to load data from multiple different files. It is cumbersome, however, as the the user will have to choose a file, load the data, choose the next file, load data, etc. Loading data from tens of files or more will end up becoming an annoyance, rather than a helpful tool.

The solution to this, is to allow the user to select multiple files to load data from. Instead of a drop down menu, a menu that allows the user to select which files to load from would be a lot more user friendly.

\subsection{Performance of heat map generation}
\label{Issues_GenerationPerformance}

As described in section \ref{Testing_Performance_Generating}, generating the heat map becomes slower the more points that are being loaded and processed, because of the $O(n^2 + n)$ run time.

There are a couple of ways to address this issue. The first way would be to do the data processing on a separate machine. Simply choose all the data that was to be used, process it, save it to a different XML format and then load that format instead. The processing could either happen on another computer, or on a server dedicated to heat mapping data. It would still be slow, but it would not stop the developer from doing anything while the heat map was being generated.

Another way would be make a binned heat map instead of the current version. Instead of coloring areas of varying sizes, the map is split into x by y squares. The events are run through, and every event inside a square increases the density of that square. After all events have been run through, the squares are colored (see \refFig{HM_B} on page \pageref{fig:HM_B} for an example). This way, the run time would be reduced to $O(n + m)$ (n being the amount of events and m being the amount of squares), which is considerably faster than $O(n^2 + n)$.

The trade-off is that a binned heat map is a top-down picture. Therefore, if the game a developer is working with has multiple floors linked together and they are on top of each other, he would have to generate a heat map for each floor, thus resulting in a run time of $O(h * (n + m))$ (where h is the amount of height maps to generate). As long as there are fewer heat maps to generate than there are events, it would still be a lot cheaper performance wise.

\insertPictureS{0.7}{HeatMap_Binned}{A binned heat map.}{HM_B}

\subsection{Object names when tracking}
\label{Issues_UniqueNames}

For each object that is being tracked, the object will create a file named "HeatMapData<objectName>.xml" and open an XmlTextWriter to that file. This causes a problem when multiple objects have the same name, as they will overwrite previous files. For example, if ten \textit{Enemy} objects are being tracked, only the last one to be loaded will have a file to write to, and the other nine will lack the file their writer is linked to. Thus only one object will actually be tracked.

The simple way to solve this problem, is to check if the file already exits, and in that case append a number to the end of the new file name. This would leave a lot of "HeatMapData<objectName><number>.xml" files in the session folder, but as the user will never have to interact with these files, it should not be an issue.

\subsection{Unity 2D tool support}
\label{Issues_2DSupport}

In version 4.3 of Unity, better 2D tools were added. As described in section \ref{Testing_Games_2D}, we found that the plug-in works when it comes to gathering data and generating a heat map from this data. However, while the heat markers were added to the scene, they were not rendered.

One way to solve this issue, would be to create a custom shader that retains some sort of transparency, while still being possible to render.